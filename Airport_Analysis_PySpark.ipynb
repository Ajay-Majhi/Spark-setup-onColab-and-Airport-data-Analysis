{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BVqTTiSE-jNi"
   },
   "source": [
    "# **Installing and Initializing Spark on Google Colab**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0BIRBEhu-0Eu"
   },
   "outputs": [],
   "source": [
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz\n",
    "\n",
    "!tar xf spark-3.0.2-bin-hadoop2.7.tgz\n",
    "\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "x6us2lUp_Txh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "2qL5BQ_c_W0W",
    "outputId": "d1543145-992c-471a-997a-d1d712045052"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content/spark-3.2.1-bin-hadoop3.2'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "_wcoEUk5_cfH"
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Unable to find py4j in /content/spark-3.2.1-bin-hadoop3.2/python, your SPARK_HOME may not be configured correctly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/findspark.py:159\u001b[0m, in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     py4j \u001b[38;5;241m=\u001b[39m \u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspark_python\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlib\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpy4j-*.zip\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfindspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/findspark.py:161\u001b[0m, in \u001b[0;36minit\u001b[0;34m(spark_home, python_path, edit_rc, edit_profile)\u001b[0m\n\u001b[1;32m    159\u001b[0m         py4j \u001b[38;5;241m=\u001b[39m glob(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(spark_python, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlib\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpy4j-*.zip\u001b[39m\u001b[38;5;124m\"\u001b[39m))[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find py4j in \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, your SPARK_HOME may not be configured correctly\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    163\u001b[0m                 spark_python\n\u001b[1;32m    164\u001b[0m             )\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath[:\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m sys_path \u001b[38;5;241m=\u001b[39m [spark_python, py4j]\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# already imported, no need to patch sys.path\u001b[39;00m\n",
      "\u001b[0;31mException\u001b[0m: Unable to find py4j in /content/spark-3.2.1-bin-hadoop3.2/python, your SPARK_HOME may not be configured correctly"
     ]
    }
   ],
   "source": [
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "erwZOUo8_oyv"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/spark-3.2.1-bin-hadoop3.2/./bin/spark-submit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[0;32m----> 3\u001b[0m spark \u001b[38;5;241m=\u001b[39m \u001b[43mSparkSession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuilder\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaster\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlocal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappName\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColab\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspark.ui.port\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m4050\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SQLContext\n\u001b[1;32m     10\u001b[0m sqlContext \u001b[38;5;241m=\u001b[39m SQLContext(spark)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/sql/session.py:269\u001b[0m, in \u001b[0;36mSparkSession.Builder.getOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    267\u001b[0m     sparkConf\u001b[38;5;241m.\u001b[39mset(key, value)\n\u001b[1;32m    268\u001b[0m \u001b[38;5;66;03m# This SparkContext may be an existing one.\u001b[39;00m\n\u001b[0;32m--> 269\u001b[0m sc \u001b[38;5;241m=\u001b[39m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetOrCreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparkConf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;66;03m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[39;00m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# by all sessions.\u001b[39;00m\n\u001b[1;32m    272\u001b[0m session \u001b[38;5;241m=\u001b[39m SparkSession(sc, options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/context.py:483\u001b[0m, in \u001b[0;36mSparkContext.getOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    482\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 483\u001b[0m         \u001b[43mSparkContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mSparkConf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    485\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_active_spark_context\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/context.py:195\u001b[0m, in \u001b[0;36mSparkContext.__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls, udf_profiler_cls)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m gateway \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m gateway\u001b[38;5;241m.\u001b[39mgateway_parameters\u001b[38;5;241m.\u001b[39mauth_token \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to pass an insecure Py4j gateway to Spark. This\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is not allowed as it is a security risk.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m     )\n\u001b[0;32m--> 195\u001b[0m \u001b[43mSparkContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_initialized\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgateway\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgateway\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    197\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_do_init(\n\u001b[1;32m    198\u001b[0m         master,\n\u001b[1;32m    199\u001b[0m         appName,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m         udf_profiler_cls,\n\u001b[1;32m    209\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/context.py:417\u001b[0m, in \u001b[0;36mSparkContext._ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SparkContext\u001b[38;5;241m.\u001b[39m_gateway:\n\u001b[0;32m--> 417\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_gateway \u001b[38;5;241m=\u001b[39m gateway \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mlaunch_gateway\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    418\u001b[0m         SparkContext\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;241m=\u001b[39m SparkContext\u001b[38;5;241m.\u001b[39m_gateway\u001b[38;5;241m.\u001b[39mjvm\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m instance:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pyspark/java_gateway.py:96\u001b[0m, in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m         signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, signal\u001b[38;5;241m.\u001b[39mSIG_IGN)\n\u001b[1;32m     95\u001b[0m     popen_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreexec_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m preexec_func\n\u001b[0;32m---> 96\u001b[0m     proc \u001b[38;5;241m=\u001b[39m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpopen_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# preexec_fn not supported on Windows\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     proc \u001b[38;5;241m=\u001b[39m Popen(command, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpopen_kwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py:854\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, encoding, errors, text)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    851\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    852\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 854\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    856\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    862\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/subprocess.py:1702\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1700\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1701\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1702\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1703\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/spark-3.2.1-bin-hadoop3.2/./bin/spark-submit'"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Colab\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 214
    },
    "id": "_zN-fJSA_twW",
    "outputId": "1773b3f9-c270-4051-b1c3-18f6f793ff81"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bee0e9ea0b55:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Colab</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ff9bb0a7210>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_TDT7b2x99xW"
   },
   "source": [
    "# **Reading CSV File using Spark**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "0VeeTW-eAKFv"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39mcsv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAirports2.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, inferSchema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m df\u001b[38;5;241m.\u001b[39mregisterTempTable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"Airports2.csv\", header=True, inferSchema=True)\n",
    "df.registerTempTable('df')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzXNqV9V-HE0"
   },
   "source": [
    "# **Basic Insights into Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gRstmRZmAWiz",
    "outputId": "1ccb8bdb-db74-4f7e-ce72-81495064d282"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Origin_airport: string (nullable = true)\n",
      " |-- Destination_airport: string (nullable = true)\n",
      " |-- Origin_city: string (nullable = true)\n",
      " |-- Destination_city: string (nullable = true)\n",
      " |-- Passengers: integer (nullable = true)\n",
      " |-- Seats: integer (nullable = true)\n",
      " |-- Flights: integer (nullable = true)\n",
      " |-- Distance: integer (nullable = true)\n",
      " |-- Fly_date: string (nullable = true)\n",
      " |-- Origin_population: integer (nullable = true)\n",
      " |-- Destination_population: integer (nullable = true)\n",
      " |-- Org_airport_lat: string (nullable = true)\n",
      " |-- Org_airport_long: string (nullable = true)\n",
      " |-- Dest_airport_lat: string (nullable = true)\n",
      " |-- Dest_airport_long: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aR1atRnSAjpn",
    "outputId": "aa2a6faf-1aef-485d-ac88-9dece26348d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3606803"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0lw2qIQAuLX",
    "outputId": "b5505d38-7833-4852-ad21-e3a9bfaf6a2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+-------------------+--------------+----------------+------------------+-----------------+------------------+-----------------+----------+-----------------+----------------------+------------------+------------------+-----------------+------------------+\n",
      "|summary|Origin_airport|Destination_airport|   Origin_city|Destination_city|        Passengers|            Seats|           Flights|         Distance|  Fly_date|Origin_population|Destination_population|   Org_airport_lat|  Org_airport_long| Dest_airport_lat| Dest_airport_long|\n",
      "+-------+--------------+-------------------+--------------+----------------+------------------+-----------------+------------------+-----------------+----------+-----------------+----------------------+------------------+------------------+-----------------+------------------+\n",
      "|  count|       3606803|            3606803|       3606803|         3606803|           3606803|          3606803|           3606803|          3606803|   3606803|          3606803|               3606803|           3606803|           3606803|          3606803|           3606803|\n",
      "|   mean|          null|               null|          null|            null|2688.9104331453646|4048.297368888736| 37.22889855642241|697.3190326724249|      null| 5871502.49894491|      5897982.44118434|37.750289955901664|-91.86177935715813|37.74090832973531|-91.83432738662697|\n",
      "| stddev|          null|               null|          null|            null|  4347.61704769634|6200.871210153885|49.619697799496414|604.4165108483492|      null|7858061.601821028|     7906127.406405261| 5.765453283976701|16.537733702683525|5.736555536048647|16.472284529884853|\n",
      "|    min|           1B1|                1B1|  Aberdeen, SD|    Aberdeen, SD|                 0|                0|                 0|                0|1990-01-01|            13005|                 12887|   19.721399307251|      -100.2860031|  19.721399307251|      -100.2860031|\n",
      "|    max|           ZZV|                ZZV|Zanesville, OH|  Zanesville, OH|             89597|           147062|              1128|             5095|2009-12-01|         38139592|              38139592|                NA|                NA|               NA|                NA|\n",
      "+-------+--------------+-------------------+--------------+----------------+------------------+-----------------+------------------+-----------------+----------+-----------------+----------------------+------------------+------------------+-----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwEHr9pv-MB5"
   },
   "source": [
    "# **Spark Transformation and Action Operations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0BXUCJS1AdvE",
    "outputId": "7e4f20dd-748b-408c-af26-427d1b527b87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+-------------+----------------+----------+-----+-------+--------+----------+-----------------+----------------------+----------------+-----------------+----------------+-----------------+\n",
      "|Origin_airport|Destination_airport|  Origin_city|Destination_city|Passengers|Seats|Flights|Distance|  Fly_date|Origin_population|Destination_population| Org_airport_lat| Org_airport_long|Dest_airport_lat|Dest_airport_long|\n",
      "+--------------+-------------------+-------------+----------------+----------+-----+-------+--------+----------+-----------------+----------------------+----------------+-----------------+----------------+-----------------+\n",
      "|           MHK|                AMW|Manhattan, KS|        Ames, IA|        21|   30|      1|     254|2008-10-01|           122049|                 86219| 39.140998840332|-96.6707992553711|              NA|               NA|\n",
      "|           EUG|                RDM|   Eugene, OR|        Bend, OR|        41|  396|     22|     103|1990-11-01|           284093|                 76034|44.1245994567871| -123.21199798584|      44.2541008|     -121.1500015|\n",
      "|           EUG|                RDM|   Eugene, OR|        Bend, OR|        88|  342|     19|     103|1990-12-01|           284093|                 76034|44.1245994567871| -123.21199798584|      44.2541008|     -121.1500015|\n",
      "|           EUG|                RDM|   Eugene, OR|        Bend, OR|        11|   72|      4|     103|1990-10-01|           284093|                 76034|44.1245994567871| -123.21199798584|      44.2541008|     -121.1500015|\n",
      "|           MFR|                RDM|  Medford, OR|        Bend, OR|         0|   18|      1|     156|1990-02-01|           147300|                 76034|42.3741989135742|-122.873001098633|      44.2541008|     -121.1500015|\n",
      "+--------------+-------------------+-------------+----------------+----------+-----+-------+--------+----------+-----------------+----------------------+----------------+-----------------+----------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IvAsTyn3AnK_",
    "outputId": "42852508-ef31-4b30-ce3a-bcebe90c41f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+----------+-----+\n",
      "|Origin_airport|Destination_airport|Passengers|Seats|\n",
      "+--------------+-------------------+----------+-----+\n",
      "|           MHK|                AMW|        21|   30|\n",
      "|           EUG|                RDM|        41|  396|\n",
      "|           EUG|                RDM|        88|  342|\n",
      "|           EUG|                RDM|        11|   72|\n",
      "|           MFR|                RDM|         0|   18|\n",
      "|           MFR|                RDM|        11|   18|\n",
      "|           MFR|                RDM|         2|   72|\n",
      "|           MFR|                RDM|         7|   18|\n",
      "|           MFR|                RDM|         7|   36|\n",
      "|           SEA|                RDM|         8|   18|\n",
      "|           SEA|                RDM|       453| 3128|\n",
      "|           SEA|                RDM|       784| 2720|\n",
      "|           SEA|                RDM|       749| 2992|\n",
      "|           SEA|                RDM|        11|   18|\n",
      "|           PDX|                RDM|       349|  851|\n",
      "+--------------+-------------------+----------+-----+\n",
      "only showing top 15 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"Origin_airport\",\"Destination_airport\",\"Passengers\",\"Seats\").show(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YKz7gfpaAzrm",
    "outputId": "45a163a7-d492-452b-f990-c087e47a2e9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+\n",
      "|Origin_airport|sum(Passengers)|\n",
      "+--------------+---------------+\n",
      "|           BGM|        1876537|\n",
      "|           CRS|             29|\n",
      "|           VWD|              0|\n",
      "|           MOR|              0|\n",
      "|           MSY|       83279662|\n",
      "|           RDG|          87401|\n",
      "|           GEG|       23872254|\n",
      "|           DRT|          75152|\n",
      "|           HVR|           1193|\n",
      "|           MML|              0|\n",
      "+--------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "airportAgg_DF = df.groupBy(\"Origin_airport\").agg(F.sum(\"Passengers\"))\n",
    "airportAgg_DF.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ul8pv3nR-Ygi"
   },
   "source": [
    "# **Spark SQL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HKCP7j9gcDnN"
   },
   "source": [
    "## **Highest Flight Departures Airport**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h93KQAGABQ23",
    "outputId": "da0a01a1-a18a-4256-c38c-5dcdafc74fcc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|Origin_Airport|Flights|\n",
      "+--------------+-------+\n",
      "|           ORD|6908482|\n",
      "|           ATL|6558015|\n",
      "|           DFW|5994638|\n",
      "|           LAX|4099901|\n",
      "|           DTW|3452613|\n",
      "|           PHX|3213108|\n",
      "|           MSP|3204923|\n",
      "|           IAH|3195062|\n",
      "|           STL|3181102|\n",
      "|           CLT|2840773|\n",
      "+--------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "originAirports = sqlContext.sql(\"\"\"select Origin_Airport, sum(Flights) as Flights \n",
    "                                    from df group by Origin_Airport order by sum(Flights) DESC limit 10\"\"\")\n",
    "originAirports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJdfcSQOcZgo"
   },
   "source": [
    "## **Highest Passenger Arrival Airport**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "03ITa_gmGCxA",
    "outputId": "e89ddc7e-5d98-4a45-a1f4-6db06d938c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+\n",
      "|Destination_airport|Passengers|\n",
      "+-------------------+----------+\n",
      "|                ATL| 577954147|\n",
      "|                ORD| 528648148|\n",
      "|                DFW| 458322527|\n",
      "|                LAX| 389476602|\n",
      "|                PHX| 295580444|\n",
      "|                LAS| 269145891|\n",
      "|                DTW| 251467874|\n",
      "|                MSP| 245774036|\n",
      "|                SFO| 242283245|\n",
      "|                IAH| 229105403|\n",
      "+-------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "destinationAirports = sqlContext.sql(\"\"\"select Destination_airport, sum(Passengers) as Passengers \n",
    "                                    from df group by Destination_airport order by sum(Passengers) DESC limit 10\"\"\")\n",
    "destinationAirports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biRXKITtcdoJ"
   },
   "source": [
    "## **Airports with Most Flights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u_1r47arHomo",
    "outputId": "4dbb33b0-74ce-453b-858b-08afd6d70566"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n",
      "|Airport|Total_Flights|\n",
      "+-------+-------------+\n",
      "|    ORD|     13804767|\n",
      "|    ATL|     13102774|\n",
      "|    DFW|     11982524|\n",
      "|    LAX|      8196603|\n",
      "|    DTW|      6900655|\n",
      "|    PHX|      6421985|\n",
      "|    MSP|      6405105|\n",
      "|    IAH|      6391830|\n",
      "|    STL|      6358741|\n",
      "|    CLT|      5677880|\n",
      "|    EWR|      5620104|\n",
      "|    LGA|      5368743|\n",
      "|    PHL|      5344278|\n",
      "|    SEA|      5158456|\n",
      "|    LAS|      5040914|\n",
      "+-------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MostFlightsByAirports = sqlContext.sql(\"\"\"with destination as (select Destination_airport as Airport, sum(Flights) as Out_Flights \n",
    "                                    from df group by Destination_airport),\n",
    "                                    origin as (select Origin_airport as Airport, sum(Flights) as In_Flights \n",
    "                                    from df group by Origin_airport)\n",
    "                                    select origin.Airport, (destination.Out_Flights+origin.In_Flights) as Total_Flights\n",
    "                                    from origin, destination \n",
    "                                    where origin.Airport = destination.Airport\n",
    "                                    order by (origin.In_Flights + destination.Out_Flights) DESC\n",
    "                                    limit 15\"\"\")\n",
    "MostFlightsByAirports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQvKMn-Gcml2"
   },
   "source": [
    "## **Airports with Most Passengers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV3D1J6FK7tT",
    "outputId": "e17fac6f-be0d-446c-8776-f9582e8e2266"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------------+\n",
      "|Airport|Total_Passengers|\n",
      "+-------+----------------+\n",
      "|    DFW|     64193553706|\n",
      "|    ATL|     62429740643|\n",
      "|    ORD|     56896329462|\n",
      "|    LAX|     53533015275|\n",
      "|    LGA|     32947558489|\n",
      "|    PHX|     32559529060|\n",
      "|    LAS|     29100039374|\n",
      "|    SFO|     27096863160|\n",
      "|    BOS|     24112128142|\n",
      "|    SEA|     23575268222|\n",
      "|    HNL|     23235437905|\n",
      "|    DCA|     20108810076|\n",
      "|    MCO|     19771422559|\n",
      "|    IAH|     19289444015|\n",
      "|    STL|     19122558315|\n",
      "+-------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MostPassengersByAirports = sqlContext.sql(\"\"\"with destination as (select Destination_airport as Airport, sum(Passengers*Flights) as Out_Passengers \n",
    "                                    from df group by Destination_airport),\n",
    "                                    origin as (select Origin_airport as Airport, sum(Passengers) as In_Passengers\n",
    "                                    from df group by Origin_airport)\n",
    "                                    select origin.Airport, (destination.Out_Passengers+origin.In_Passengers) as Total_Passengers\n",
    "                                    from origin, destination \n",
    "                                    where origin.Airport = destination.Airport\n",
    "                                    order by (origin.In_Passengers + destination.Out_Passengers) DESC\n",
    "                                    limit 15\"\"\")\n",
    "MostPassengersByAirports.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-EIXuLp3GU9"
   },
   "source": [
    "## **Occupancy Rates for Routes with Most Flights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5WO8R--kJEqY",
    "outputId": "74317df1-46ec-4d5b-9213-535675812ae8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+-------+----------+--------+------------------+\n",
      "|Airport1|Airport2|Flights|Passengers|   Seats|    Occupancy_Rate|\n",
      "+--------+--------+-------+----------+--------+------------------+\n",
      "|     HNL|     OGG| 784873|  62109354|96640901| 64.26818599300931|\n",
      "|     LAX|     SFO| 636449|  51119989|79405656|  64.3782717442697|\n",
      "|     LAS|     LAX| 588151|  52511530|80532768| 65.20517213564546|\n",
      "|     PDX|     SEA| 565707|  18475771|34650955| 53.31965886654495|\n",
      "|     LAX|     PHX| 515093|  42695385|65619395| 65.06519147273455|\n",
      "|     BOS|     LGA| 470737|  31242486|64897330| 48.14140427657039|\n",
      "|     MSP|     ORD| 467514|  31301666|55325318|56.577471457100344|\n",
      "|     LAS|     PHX| 460104|  42979048|64844100| 66.28058373853597|\n",
      "|     DCA|     LGA| 439107|  29471657|60663368|   48.582295991215|\n",
      "|     LAX|     SAN| 431076|  11686171|22820096|51.209999291852235|\n",
      "|     LGA|     ORD| 424272|  39981416|59616532| 67.06431028225526|\n",
      "|     DAL|     HOU| 408273|  35573141|53054549| 67.05012420329876|\n",
      "|     ATL|     DFW| 399696|  42941213|59978776| 71.59401352238332|\n",
      "|     LAX|     OAK| 381677|  30429561|47045709| 64.68084262477583|\n",
      "|     EWR|     ORD| 372054|  31122785|50434853| 61.70888413216947|\n",
      "+--------+--------+-------+----------+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distanceQuery = sqlContext.sql(\"\"\"with table1 as \n",
    "                                    (select least(Origin_airport, Destination_airport) as Airport1, \n",
    "                                    greatest(Destination_airport, Origin_airport) as Airport2, \n",
    "                                    sum(Flights) as Flights,\n",
    "                                    sum(Passengers) as Passengers,\n",
    "                                    sum(Seats) as Seats\n",
    "                                    from df\n",
    "                                    group by least(Origin_airport, Destination_airport), greatest(Destination_airport, Origin_airport)\n",
    "                                    order by 1,2)\n",
    "                                    select t.*, (Passengers*100/Seats) as Occupancy_Rate\n",
    "                                    from table1 t\n",
    "                                    order by Flights DESC, Seats DESC, Passengers DESC, Occupancy_Rate DESC\n",
    "                                    limit 15;\"\"\")\n",
    "distanceQuery = distanceQuery.filter((col(\"Occupancy_Rate\").isNotNull()) & (col(\"Occupancy_Rate\")<=100.0))\n",
    "distanceQuery.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5K1z2Wjy9Q4q"
   },
   "source": [
    "## **Number of Flights vs Distance - Part 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NtwG1fxboqS_",
    "outputId": "8960db55-4371-4ce9-da71-1a5601be3f1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+--------+-------+\n",
      "|Airport1|Airport2|Distance|Flights|\n",
      "+--------+--------+--------+-------+\n",
      "|     BDL|     HNL|  5018.0|      3|\n",
      "|     HNL|     JFK|  4983.0|    430|\n",
      "|     HIK|     JFK|  4983.0|      3|\n",
      "|     HNL|     LGA|  4976.0|      1|\n",
      "|     EWR|     HNL|  4962.0|   8320|\n",
      "|     JFK|     OGG|  4924.0|      1|\n",
      "|     HNL|     PHL|  4919.0|      1|\n",
      "|     HIK|     MIA|  4862.0|      1|\n",
      "|     HNL|     MIA|  4862.0|      9|\n",
      "|     HNL|     ISO|  4860.0|      1|\n",
      "|     OGG|     PHL|  4859.0|      1|\n",
      "|     BWI|     HNL|  4855.0|      7|\n",
      "|     HNL|     IAD|  4817.0|      3|\n",
      "|     BWI|     OGG|  4793.0|      1|\n",
      "|     HIK|     POB|  4785.0|      1|\n",
      "+--------+--------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distanceQuery = sqlContext.sql(\"\"\"with table1 as \n",
    "                                    (select least(Origin_airport, Destination_airport) as Airport1, \n",
    "                                    greatest(Destination_airport, Origin_airport) as Airport2, \n",
    "                                    mean(Distance) as Distance,\n",
    "                                    sum(Flights) as Flights\n",
    "                                    from df\n",
    "                                    group by least(Origin_airport, Destination_airport), greatest(Destination_airport, Origin_airport)\n",
    "                                    order by 1,2)\n",
    "                                    select t.*\n",
    "                                    from table1 t\n",
    "                                    where Flights>0\n",
    "                                    order by Distance DESC\n",
    "                                    limit 15;\"\"\")\n",
    "# distanceQuery = distanceQuery.filter((col(\"Occupancy_Rate\").isNotNull()) & (col(\"Occupancy_Rate\")<=100.0))\n",
    "distanceQuery.show(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdUeHE_C9gGk"
   },
   "source": [
    "## **Number of Flights vs Distance - Part 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0wO-6g-p3kcr",
    "outputId": "88dfb925-8e9f-421d-c31c-60b54956ba48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+------------------+-------+\n",
      "|Airport1|Airport2|          Distance|Flights|\n",
      "+--------+--------+------------------+-------+\n",
      "|     HNL|     OGG|             100.0| 784873|\n",
      "|     LAX|     SFO|             337.0| 636449|\n",
      "|     LAS|     LAX|             236.0| 588151|\n",
      "|     PDX|     SEA|             129.0| 565707|\n",
      "|     LAX|     PHX|             370.0| 515093|\n",
      "|     BOS|     LGA|             185.0| 470737|\n",
      "|     MSP|     ORD|             334.0| 467514|\n",
      "|     LAS|     PHX|255.96021840873635| 460104|\n",
      "|     DCA|     LGA|             214.0| 439107|\n",
      "|     LAX|     SAN|             109.0| 431076|\n",
      "|     LGA|     ORD|             733.0| 424272|\n",
      "|     DAL|     HOU|             239.0| 408273|\n",
      "|     ATL|     DFW| 731.9746309301993| 399696|\n",
      "|     LAX|     OAK|             337.0| 381677|\n",
      "|     EWR|     ORD|             719.0| 372054|\n",
      "+--------+--------+------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distanceQuery = sqlContext.sql(\"\"\"with table1 as \n",
    "                                    (select least(Origin_airport, Destination_airport) as Airport1, \n",
    "                                    greatest(Destination_airport, Origin_airport) as Airport2, \n",
    "                                    mean(Distance) as Distance,\n",
    "                                    sum(Flights) as Flights\n",
    "                                    from df\n",
    "                                    group by least(Origin_airport, Destination_airport), greatest(Destination_airport, Origin_airport)\n",
    "                                    order by 1,2)\n",
    "                                    select t.*\n",
    "                                    from table1 t\n",
    "                                    where Flights>0\n",
    "                                    order by Flights DESC\n",
    "                                    limit 15;\"\"\")\n",
    "# distanceQuery = distanceQuery.filter((col(\"Occupancy_Rate\").isNotNull()) & (col(\"Occupancy_Rate\")<=100.0))\n",
    "distanceQuery.show(15)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Airport_Analysis_PySpark.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
